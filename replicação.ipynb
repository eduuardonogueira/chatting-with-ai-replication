{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTX2njw1glDs"
      },
      "source": [
        "Replicação - Equipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx7qayDtg3j-"
      },
      "source": [
        "- snapshot_20230727\n",
        "- pegaram 100 conversas para montar as categorias\n",
        "- resultou em 22 categorias\n",
        "- 95% de confiança e 5% de erro\n",
        "- Qualquer conversa que não estiver disponível e não for em inglês, descarta (N/A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhoEcKDsqcmv"
      },
      "source": [
        "Importando o dataset em json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "bfcb97d5",
        "outputId": "60da45ac-c56d-44f8-a8ed-68161ee3e334"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "discussion_json_path = './datasets/20230727_195954_discussion_sharings.json'\n",
        "hn_sharings_json_path = './datasets/20230727_195816_hn_sharings.json'\n",
        "\n",
        "with open(discussion_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    discussion_data = json.load(f)\n",
        "\n",
        "with open(hn_sharings_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    hn_sharings_data = json.load(f)\n",
        "\n",
        "discussion_sources = discussion_data.get(\"Sources\", [])\n",
        "hn_sources = hn_sharings_data.get(\"Sources\", [])\n",
        "\n",
        "sources = discussion_sources + hn_sources\n",
        "rows = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSOdXo5aDlDC"
      },
      "source": [
        "percorre o JSON das fontes e conversas do ChatGPT, filtra apenas os prompts feitos pelos usuários e transforma cada prompt em uma linha estruturada com metadados para análise em um DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA0bwKSg3Lbb"
      },
      "outputs": [],
      "source": [
        "for src in sources:\n",
        "    chat_sharings = src.get(\"ChatgptSharing\", []) or []\n",
        "    for share in chat_sharings:\n",
        "        conversations = share.get(\"Conversations\", []) or []\n",
        "        for idx, turn in enumerate(conversations):\n",
        "            prompt = turn.get(\"Prompt\")\n",
        "            if prompt is None:\n",
        "                continue\n",
        "\n",
        "            rows.append({\n",
        "                \"source_type\": src.get(\"Type\"),\n",
        "                \"source_url\": src.get(\"URL\"),\n",
        "                \"source_title\": src.get(\"Title\"),\n",
        "                \"chat_url\": share.get(\"URL\"),\n",
        "                \"chat_title\": share.get(\"Title\"),\n",
        "                \"date_of_conversation\": share.get(\"DateOfConversation\"),\n",
        "                \"status\": share.get(\"Status\"),\n",
        "                \"prompt_index\": idx,\n",
        "                \"prompt\": prompt\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaF_CHk5DhZZ"
      },
      "source": [
        "Limpeza do texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEfns8eADgq1"
      },
      "outputs": [],
      "source": [
        "if not df.empty:\n",
        "    df[\"prompt\"] = (\n",
        "        df[\"prompt\"]\n",
        "        .astype(str)\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "    df = df[df[\"prompt\"].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "print(f\"Total de prompts extraídos: {len(df)}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIuUc-na5gIb"
      },
      "outputs": [],
      "source": [
        "\"\"\"Tratamentos\"\"\"\n",
        "\n",
        "\n",
        "# Função para remover os textos que não estão em inglês.\n",
        "def is_english(text):\n",
        "    if not isinstance(text, str):\n",
        "        return False\n",
        "    return bool(re.match(r\"^[\\x00-\\x7F]+$\", text))\n",
        "\n",
        "\n",
        "# Aplicando o filtro no dataframe.\n",
        "df[\"is_english\"] = df[\"prompt\"].apply(is_english)\n",
        "\n",
        "df_lang = df[df[\"is_english\"]].reset_index(drop=True)\n",
        "\n",
        "print(f\"Após filtro de idioma (inglês): {len(df_lang)}\")\n",
        "\n",
        "# Realizar uma última verificação para garantir que os dados estejam filtrados de maneira adequada.\n",
        "df_final = df_lang[\n",
        "    df_lang[\"prompt\"].notna() & (df_lang[\"prompt\"].str.len() > 5)\n",
        "].reset_index(drop=True)\n",
        "\n",
        "print(f\"Dataset final após todos os filtros: {len(df_final)}\")\n",
        "\n",
        "df_final.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
